# -*- coding: utf-8 -*-
"""Proyek 2 : Membuat Model Machine Learning dengan Data Time Series.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lR7LxFh2mNH9MdmjW-NkwKQypiY8E-4t

Nama : Yolanda Ester Berliana Ritonga

Email : yolandaesterbrtg@gmail.com

Kelas : Belajar Pengembangan Machine Learning

**Import Libraries**
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error
import tensorflow as tf
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard
import matplotlib.pyplot as plt

"""**Load Data**"""

data = pd.read_csv('Occupancy_Estimation.csv')

"""**Informasi Data**"""

total_data = data.shape[0]
print(f'Total Data: {total_data} rows')
print("Columns:", data.columns)
print("Data:")
print(data.head())

"""**Preprocess Data**"""

data = data.drop(['Date', 'Time'], axis=1)

scaler = MinMaxScaler(feature_range=(-1, 1))
data_scaled = scaler.fit_transform(data)

"""**Prepare Data**"""

X = data_scaled[:, :-1]
y = data_scaled[:, -1]

"""**Split Data**"""

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, shuffle=False)

X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])
X_val = X_val.reshape(X_val.shape[0], 1, X_val.shape[1])

"""**Build Model**"""

model = Sequential()
model.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))
model.add(LSTM(50))
model.add(Dense(1))

"""**Compile Model**"""

optimizer = Adam(learning_rate=0.001)
model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])

"""**Set Up Callbacks**"""

callbacks = [
    ModelCheckpoint('best_model.h5', save_best_only=True),
    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),
    TensorBoard(log_dir='./logs')
]

"""**Train Model**"""

history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), callbacks=callbacks)

"""**Load Best Model**"""

best_model = load_model('best_model.h5')

"""**Make Predictions**"""

y_pred = best_model.predict(X_val)

y_pred = scaler.inverse_transform(np.concatenate((X_val.reshape(X_val.shape[0], X_val.shape[2]), y_pred.reshape(y_pred.shape[0], 1)), axis=1))[:, -1]
y_true = scaler.inverse_transform(np.concatenate((X_val.reshape(X_val.shape[0], X_val.shape[2]), y_val.reshape(y_val.shape[0], 1)), axis=1))[:, -1]

"""**Evaluate Model**"""

mae = mean_absolute_error(y_true, y_pred)
data_scale = y.max() - y.min()
mae_percentage = (mae / data_scale) * 100

mae_threshold = 0.1 * data_scale

if mae < mae_threshold:
    print(f'MAE: {mae_percentage:.2f}% is less than 10% of data scale. Model is acceptable.')
else:
    print(f'MAE: {mae_percentage:.2f}% exceeds 10% of data scale. Model needs improvement.')

"""**Plot Training and Validation Loss**"""

plt.figure(figsize=(12, 6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

"""**Plot Training and Validation MAE**"""

plt.figure(figsize=(12, 6))
plt.plot(history.history['mae'], label='Training MAE')
plt.plot(history.history['val_mae'], label='Validation MAE')
plt.title('Training and Validation MAE')
plt.xlabel('Epochs')
plt.ylabel('MAE')
plt.legend()
plt.show()